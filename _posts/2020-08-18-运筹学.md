# 运筹学 - 理论

* only for continuous optimization
* Convex optimization
* Theory
* Algorithms

## Convexity 

###### Convex Sets & Hull

我们一般会要求这个假设。

<div style = "background-color:#d0e1e1" markdown = "1">
A set $$ S \subset \mathbb{R}^{n}$$ is a __convex set__ if $$ \forall x_1, x_2 \in S, \, \lambda \in (0,1), \lambda x_1 + (1- \lambda) \in S$$
</div>

<div style = "background-color:#d0e1e1" markdown = "1">
A __convex hull__ of S, $$conv(S)$$ is the set 

$$
\begin{align*}
	conv(S)  &=  \bigg\{ \sum_{j = 1}^{k} \lambda_j x_j : \sum_{j =1}^{k} \lambda_j = 1, \lambda_j \ge 0. x_j \in S, k = 1,2,... \bigg\} \\
\end{align*}
$$

</div>

- 为什么这里需要一个 k, 我理解的是, 这个set S 有可能是个无穷集, k 只是一个arbitrarily large  的数。

如果 S 是有限集的话, 我觉得这个定义完全可以这么写：

$$
conv(S) = \bigg\{ \sum_{j = 1}^{|S|} \lambda_j x_j : \sum_{j =1}^{|S|} \lambda_j = 1, \lambda_j \ge 0. x_j \in S \bigg\} 
$$




两个比较之下其实很好理解, __Convex Set__ 就只是任意两个点之间的所有点, 在2维的图像里, 如果有三个点, 假设这三个顶点都在这个set, 那么这个set 就会覆一个三角形的三条边; 而 __Convex Hull__ 就是里面任意几个点之间的所有点, 就会形成这个三角形的整个面积.


##### Lemma Convex Hull of S is the smallest convex set containing S.

第二个定义： $$conv(S) $$ 是所以包含S 的convex set 的交集。 (不同的定义可以只是我们理解问题的不同角度。不要只关注技术性的等价关系)
<details markdown="1" style="background-color: #f0f0f5">
<summary> 点我展开证明 </summary>
Proof:
其实只要3点：
1. $$ conv(S) \supseteq S$$
2. $$ conv(S) \text{ is a convex set}$$
3. $$ conv(S) \subseteq H \, , \; \forall H \in C , \, \, C = \{ \text{ all convex set contains } S \}  $$

这样这个 convex hull 就是最小的一个 convex set 了, 但是还不能证明唯一。

1. is trivial 

2. 简单就是, 根据 __convex set__ 的定义, 任意两个点：

$$
\forall x_1, x_2 \in conv(S) \to \\

x_1 = \sum_{  j = 1}^{k_1} \lambda_j x_j ,\, \text{where } \sum_{j = 1}^{k_1} \lambda_j = 1\\

x_2 = \sum_{j = 1}^{  k_2} \theta_j x_j ,\, \text{where } \sum_{j = 1}^{k_2} \theta_j = 1\\
$$

要注意的是, 任意两个 $$ x_1, x_2 \in conv(x) $$ 我们都可以构造两个"长度"一样的sum, 只需令短的补一些 0 到长的就可以了。$$ k_0 = max(k_1, k_2) $$.

于是：

$$
\lambda x_1 + (1 - \lambda) x_2  = \sum_{j = 1}^{k_0} (\lambda \lambda_j + (1 - \lambda) \theta_j) x_j \\

\sum_{j = 1}^{k_0} (\lambda \lambda_j + (1 - \lambda) \theta_j) = 1 \\
$$

然后显然得我们就能证明 第二点了。

(还有一个问题是, 比如椭圆, 这显然是一个not countable set 我们可以用 k 这个countable sum来证明吗？)

第三点也是毕竟显然的。
</details>

<br>
###### $$ conv(S) $$ is closed ?

if S is open then Conv(S) is open (未考证

[if S is closed then Conv(S) is not necessary closed.](https://statisticaloddsandends.wordpress.com/2020/01/17/convex-hull-of-a-closed-set-is-not-necessarily-closed/ ":)")


##### Caratheodory's Theorem 

$$
\text{For } S \subset \mathbb{R}^{n} \text{ , all } x \in conv(S) \text{ can be written as a convex combination of at most } n + 1 \text{ points in } S.
$$

用例子最简单理解了, 2维空间, 比如有3个点, 一个三角形, 那三角形内部的点我们需要这3个点的 convex combination 才能表示。 只有两个点的话我们只能表示一个线段内部的点。 即使是一个正方形内部, 我们也可以用3个点去代表她。



<details markdown="1" style="background-color: #f0f0f5">

<summary> 点我展开证明 proof </summary>


直觉告诉我们, 肯定和linear dependant 有关, 但是要证明我个人觉得不是那么容易的;

首先整体的思路是：

1) 假设我们一个 x 可被 k 个 convex combination 表示, 并且 k > n + 1 <br>
2) 然后我们只要给出一个能 表示 x 的且 只需要 k - 1 个convex combination, 证明就完成了。

这里的难点是, 我们要清楚, 在$$ \{ x_1, x_2, ..., x_k \} $$ 里, 一定存在不全为零的$$ \{ \mu_1, \mu_2, ..., \mu_k \} $$ 使得 ：

$$
\sum_{j = 1}^{k} \mu_j x_j = 0 \\
\sum_{j = 1}^{k} \mu_j = 0
$$

这个一般是通过构造一个新的集合：$$ \{x_2 - x_1, x_3 - x_1, ..., x_k - x_1 \} $$ 这个集合的长度为 $$ k - 1 > n $$ 所以在 $$ \mathbb{R}^{n}$$ 还是linear dependant, 我们写作

$$
\sum_{j =2}^{k} ( \mu_k x_k - x_1) = 0 \, , \{ \mu_j \} \text{ not all zero} \\
\mu_1 = - \sum_{j = 2}^{k} \mu_j \\
$$

这样我们有了这个结论之后, 就比较简单了：

首先我们这个 x

$$
\begin{align*}
x &=  \sum_{j = 1}^{k} \lambda_j x_j - \boldsymbol{0}\\
  &=  \sum_{j = 1}^{k} \lambda_j x_j - \alpha \sum_{j = 1}^{k} \mu_j x_j \\
  &= \sum_{j = 1}^{k} ( \lambda - \alpha \mu_j) x_j
\end{align*}
$$

然后我们要知道 $$
\sum_{j = 1}^{k} ( \lambda_j - \alpha \mu_j ) = \sum_{j = 1}^{k} \lambda_j - \alpha \boxed{\sum_{j = 1}^{k} \mu_j} = 1$$ 因为方块里的项恒为0.

然后我们只要构造 $$ \alpha $$ 达到两个条件, 那我们的证明就结束了

(1) $$ ( \lambda_j - \alpha \mu_j) \ge 0 $$ 总成立。 <br>
(2) $$ ( \lambda_j - \alpha \mu_j) = 0 \text{ for at least one j } $$ 

答案是

$$
\alpha  = \min_{1 \le j \le k} \bigg\{ {\frac{ \lambda_j}{ \mu_j} : \mu_j > 0}   \bigg\}  = {\frac{ \lambda_i }{ \mu_i}} \text{ (assume i is the index)} 
$$

因为 <br>
(1)  <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(a) 如果 $$ \mu_j <= 0 $$ 那就是显然的. <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(b) 如果 $$ \mu > 0 $$  我们可以假设 $$ \lambda_j - \mu_j  \cdot {\frac{ \lambda_i}{ \mu_i }} > 0 = $$ 简单的化简一下等价于 $$ {\frac{ \lambda_j}{ \mu_j}} >  {\frac{ \lambda_i}{ \mu_i}} $$ 所以也是成立的。 <br>
(2) 这个也是显然的, 因为必然会有 $$ i = j$$ 的项, 自然的就是0了。


(发散一下, 构造的这个 $$ \alpha $$ 是唯一的吗？ 我个人认为是的)
</details>


##### Affine hull

<div style = "background-color:#d0e1e1" markdown = "1">
The __affine hull__ of $$ C \subset \mathbb{R}^{n} $$ is defined by: (Affine Combination)

$$
\begin{align*}
	aff C &:= \bigg\{ \sum_{k = 1}^{m} \lambda_k x^k : x^k \in C, \, k = 1,...,m, \sum_{k = 1}^{m} \lambda_k = 1, \, m \ge 1 \bigg\}   \\
\end{align*}
$$

所以相比convex hull, 就不再要求 $$ \lambda_k \ge 0 $$
</div>

同样的, 我们也说 __affine hull__ 是最小的 __affine space__ (课纲没有) containing C. 

##### Interior 


<div style = "background-color:#d0e1e1" markdown = "1">
__Interior point__  内部点
* $$S \subset \mathbb{R}^{n} $$ If exists an open ball centered at $$x$$ which contained by \\(S_{}^{}\\) .

__Interior set__ 内部(集)
  * Int S is the largest open subset of X contained in S}
  * Int S is the union of all open sets of X contained in S
  * Int S is the set of all interior points of S.

</div>


<div style = "background-color:#d0e1e1" markdown = "1">

__Relative Interior__ 相对内部点 of C is :

$$
\begin{align*}
	ri \  C &:= \{ x \in C: \exists \epsilon > 0, (x + \epsilon B^1) \cap aff C \subset C \}  \\
	B^1 &:= \{  x \in \mathbb{R}^{n} : \| x \| \le 1  \} 
\end{align*}
$$
 
</div>

比如, 在 $$ \mathbb{R}^{2}$$ 一个线段是没有 __内部点__ 的, 但我们很方便的可以有 __相对内部点__。 注意, 线段的两端的点不是相对内部点。


##### Separations of Sets

__Theorem__: 
<div style = "background-color:#d0e1e1" markdown = "1">
存在一个 $$ S \subset \mathbb{R}^{n} $$ nonempty, closed, and convex. 

只要 $$ y \notin S $$ 那么必存在 $$ \boldsymbol{p} \neq \boldsymbol{0} \in \mathbb{R}^{n} \text{ and } \alpha \in \mathbb{R} $$ such that 

$$
\begin{align*}
	\boldsymbol{p}^T y &> \alpha  \\
	\boldsymbol{p}^T y &\le \alpha  \text{ for all } x \in S\\
\end{align*} 
$$

我们说 hyperplain $$ H = \{  \boldsymbol{x} : \boldsymbol{p}^T \boldsymbol{x} = \alpha \} $$ separate \\(y_{}^{}\\) and \\(S_{}^{}\\) .
</div>

思路是这样的： 

1. 证：唯一且存在一个点 $$ x \in S $$ 这个点是离点$$y \notin S$$ 最近的点。
2. 证：主要是 triangle inequality。


<details markdown="1" style="background-color: #f0f0f5">
<summary> 第一点：点我展开证明proof </summary>
首先我们要先熟悉 __极值定理 Extreme Value Theorem (Bolzano–Weierstrass theorem)__ 

简单来说就是：
如果 $$ S $$ is compact, 然后一个 continuous function $$ f: S \to \mathbb{R}$$ 一定存在最大值和最小值。

所以首先我们最开始的假设里没有 bounded, 只有closed, 所以构造一个 bounded的 set 在 $$ \mathbb{R}^{n} $$  (Euclidean space) 就已经是 compact 了。

(暂时不细究, 不是本门课重点)

然后定义一下 $$ f(\boldsymbol{x}) = \| \boldsymbol{x} - \boldsymbol{y} \|  $$ 然后我们就能说最小值存在。

然后就是证明是唯一的。 (这就是要利用 complex 了)



 
</details>


<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
